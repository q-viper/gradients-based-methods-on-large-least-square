# gradients-based-methods-on-large-least-square
Some codes and experiments I did as a part of Master's seminar titled as `Comparing Different Gradient Based Schemes on Large Least Squared Problems`.

## What did I do?
I explored different gradient descent based parameter update techniques i.e. Optimizers on Least Squared Problems. There were lots of factor to compare optimizers and I mostly did based on the learning rate. i.e. constant LR based optimizers and adaptive LR based optimizers. I made a little suplotting and visualizer on top of Matplotlib and it is nice.


## To Do
* Clean the codes and make a package.


## Reproducing
All of the results could be reproduced from the notebooks.
* [notebooks/experiment.ipynb](notebooks/experiment.ipynb)
* [notebooks/experiment_plots.ipynb](notebooks/experiment_plots.ipynb)

## Results
* [Final Report](assets/gradient_based_methods_in_ls_final_handout.pdf)
* Plots are also in [assets](assets/)


